{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de77d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(\"archive (7).zip\", 'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b85766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order id  10718 shipping details  ship name  k...</td>\n",
       "      <td>ShippingOrder</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invoice order id  10707 customer id  arout ord...</td>\n",
       "      <td>invoice</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>order id  10448 shipping details  ship name  r...</td>\n",
       "      <td>ShippingOrder</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invoice order id  11068 customer id  queen ord...</td>\n",
       "      <td>invoice</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>order id  10656 shipping details  ship name  g...</td>\n",
       "      <td>ShippingOrder</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>order id  10326 shipping details  ship name  b...</td>\n",
       "      <td>ShippingOrder</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>purchase orders order id order date customer n...</td>\n",
       "      <td>purchase Order</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>invoice order id  10460 customer id  folko ord...</td>\n",
       "      <td>invoice</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>stock report for 2018-01 category   meat poult...</td>\n",
       "      <td>report</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>purchase orders order id order date customer n...</td>\n",
       "      <td>purchase Order</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2676 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           label  \\\n",
       "0     order id  10718 shipping details  ship name  k...   ShippingOrder   \n",
       "1     invoice order id  10707 customer id  arout ord...         invoice   \n",
       "2     order id  10448 shipping details  ship name  r...   ShippingOrder   \n",
       "3     invoice order id  11068 customer id  queen ord...         invoice   \n",
       "4     order id  10656 shipping details  ship name  g...   ShippingOrder   \n",
       "...                                                 ...             ...   \n",
       "2671  order id  10326 shipping details  ship name  b...   ShippingOrder   \n",
       "2672  purchase orders order id order date customer n...  purchase Order   \n",
       "2673  invoice order id  10460 customer id  folko ord...         invoice   \n",
       "2674  stock report for 2018-01 category   meat poult...          report   \n",
       "2675  purchase orders order id order date customer n...  purchase Order   \n",
       "\n",
       "      word_count  \n",
       "0            120  \n",
       "1             66  \n",
       "2             96  \n",
       "3             68  \n",
       "4            109  \n",
       "...          ...  \n",
       "2671         111  \n",
       "2672          39  \n",
       "2673          59  \n",
       "2674          46  \n",
       "2675          36  \n",
       "\n",
       "[2676 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"company-document-text.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8523b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# اعمل نسخة list/set من كلمات ال stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)  # إزالة الرموز\n",
    "    text = \" \".join(\n",
    "        [stemmer.stem(word) for word in text.split() if word.lower() not in stop_words]\n",
    "    )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c316278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)  # إزالة الرموز\n",
    "    text = \" \".join(\n",
    "        [stemmer.stem(word) for word in text.split() if word.lower() not in stop_words]\n",
    "    )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fdc8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']= df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a094f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb13e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df[['clean_text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06ff793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['clean_text', 'label'],\n",
       "    num_rows: 2676\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff67dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset=dataset.train_test_split(test_size=0.2,seed=42)\n",
    "train_texts=split_dataset['train']['clean_text']\n",
    "test_texts=split_dataset['test']['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e19c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48646bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"clean_text\"], padding=\"max_length\", truncation=True,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df44c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2676/2676 [00:00<00:00, 11149.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04a2654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2676/2676 [00:00<00:00, 13021.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7f7ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f0a7f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'input_ids': tensor([  101,  2344,  8909,  2911,  6987,  2911,  2171,  1047,  9152, 25394,\n",
       "          2818, 29032,  2911,  4769,  5003, 12083,  9050, 16344,  2911, 25022,\n",
       "          3775, 16426,  2911,  2555,  2530,  9944,  2361,  2911, 10690,  3642,\n",
       "          2911,  4175,  3089,  2446,  2072,  7661,  6987,  7661,  8909, 12849,\n",
       "          2368,  7661,  2171,  1047,  9152, 25394,  2818, 29032, 12666,  2063,\n",
       "          6987, 12666,  2063,  2171, 16660,  6895,  4830,  6767, 12798,  2911,\n",
       "          4842,  6987,  2911,  4842,  8909,  2911,  4842,  2171,  7349,  2121,\n",
       "          2911,  2344,  6987,  2344,  3058,  2911,  3058,  4031,  4031, 10861,\n",
       "          6499,  2158,  5403,  3995,  2474,  9220,  2050, 24110,  3775,  3775,\n",
       "          3131,  3976,  2561,  4031,  6643,  2615, 24221, 24110,  3775,  3775,\n",
       "          3131,  3976,  2561,  4031,  1999, 17802,  2094,  9033,  3363, 24110,\n",
       "          3775,  3775,  3131,  3976,  2561,  4031, 16985,  2102,  8740, 10514,\n",
       "         26775, 24110,  3775,  3775,  3131,  3976,  2561,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676f5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_45122/341654963.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [504/504 03:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=504, training_loss=0.052934169314712995, metrics={'train_runtime': 208.1014, 'train_samples_per_second': 38.577, 'train_steps_per_second': 2.422, 'total_flos': 528073370652672.0, 'train_loss': 0.052934169314712995, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0435616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/tokenizer_config.json',\n",
       " 'model/special_tokens_map.json',\n",
       " 'model/vocab.txt',\n",
       " 'model/added_tokens.json',\n",
       " 'model/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_save_path = \"model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee84232f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "folder = \"label_enocder\"\n",
    "os.makedirs(folder, exist_ok=True) \n",
    "\n",
    "label_encoder_path = os.path.join(folder, \"label_encoder.pkl\")\n",
    "\n",
    "# حفظ LabelEncoder\n",
    "joblib.dump(label_encoder, label_encoder_path)\n",
    "print(\"LabelEncoder saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aa51714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def predict(text):\n",
    "    text = clean_text(text)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        output = model(**inputs)\n",
    "        prediction = torch.argmax(output.logits, dim=-1).item()\n",
    "        return label_encoder.inverse_transform([prediction])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f0f2d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoice\n"
     ]
    }
   ],
   "source": [
    "input=\"invoice order id  10707 customer id  arout order date  2017-10-16 customer details  contact name  thomas hardy address  120 hanover sq. city  london postal code  wa1 1dp country  uk phone   171  555-7788 fax   171  555-6750 product details  product id product name quantity unit price 55 pâté chinois 21 24 0 57 ravioli angelo 40 19 5 70 outback lager 28 15 0 totalprice 1704 0 page 1\"\n",
    "print(predict(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a71b56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShippingOrder\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_text = \"order id  10345 shipping details  ship name  quick-stop ship address  taucherstraße 10 ship city  cunewalde ship region  western europe ship postal code  1307 ship country  germany customer details  customer id  quick customer name  quick-stop employee details  employee name  andrew fuller shipper details  shipper id  2 shipper name  united package order details  order date  2016-11-04 shipped date  2016-11-11 products  -------------------------------------------------------------------------------------------------- product  northwoods cranberry sauce quantity  70 unit price  32 0 total  2240 0 -------------------------------------------------------------------------------------------------- product  teatime chocolate biscuits quantity  80 unit price  7 3 total  584 0 -------------------------------------------------------------------------------------------------- product  singaporean hokkien fried mee quantity  9 unit price  11 2 total  100 8 total price  total price  2924 8\"\n",
    "print(predict(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dfbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
